07/15/2016
A very long break: husband's grandmother dying, the service, getting back to Seattle, 
getting back to life, getting sick. 

looking at tester.py today and hopefully looking at the changes I need to make
to get the SVM up and running at a decent p/r. Then, I'll try a decision tree 
classifier and then put this class to bed!

Ah, apparently I should have read my last journal entry. 

Here are the results from the DT classifer from tester.py:
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
            min_samples_split=5, min_weight_fraction_leaf=0.0,
            presort=False, random_state=0, splitter='best')
Accuracy: 0.78929       Precision: 0.25839      Recall: 0.25400 F1: 0.25618     F2: 0.25487
        Total predictions: 14000        True positives:  508    False positives: 1458   
        False negatives: 1492   True negatives: 10542

it looks like my classifier is doing equally poorly on false negs and false pos.
is this a problem with my features? What if I remove the PCA? hm, no change.

OK. Changing the min_samples_split upped the stats, but not meaningfully:
(3)
Accuracy: 0.79271       Precision: 0.27337      Recall: 0.27200 F1: 0.27268     F2: 0.27227
(1)
Accuracy: 0.79200       Precision: 0.28014      Recall: 0.29050 F1: 0.28522     F2: 0.28837

Started looking at my features list. Only looking at $, specifically:
'salary', 'exercised_stock_options', 'bonus'
helps the recall:
(1)
Accuracy: 0.76646       Precision: 0.28069      Recall: 0.33150 F1: 0.30399     F2: 0.31992
(3)
Accuracy: 0.78492       Precision: 0.30736      Recall: 0.31750 F1: 0.31235     F2: 0.31542

OK. Time to go to work


07/08/2016
Still trying to figure out my SVM problems. I have changed the kernel params, to no
effect. 
I switched to experimenting with decision trees.

07/06/2016
Experimenting with types of ML algos. I have been using the GaussianNB originally provided.
I'd like to try an SVM and a Kmeans. Decision tree doesn't seem too interesting here. 

I also tried to add precision and recall measurements to look at the differences between
these evaluations and the accuracy score when the algos change. I got an error
"UndefinedMetricWarning: Precision is ill-defined and being set to 0.0"

The GaussianNB had the following scores
accuracy 0.95
precision 1.0
recall 0.5
F1 0.666666666667

The SVM didn't make any predications. Hm. I can't find out what is up. It makes no predications.

Kmeans didn't work out for me. it predicted all the persons were POIs!! 


07/03/2016
instead of salary, I used 'total_payments' and added 'from_this_person_to_poi'
and 'from_poi_to_this_person'. That bumped my accuracy score up to 0.875!

I'll work on feature selection and PCA today, and see if I cannot come up with some 
interesting features

I was looking to run PCA or RandomizedPCA on the data, I realized I don't really know
 how to use it on the data. I understand the general concept, that it's a technique
for taking many dimensions of a dataset and distilling those dimensions to new features.

hm, I added some features, but the accuracy actually went down :(! The I added loads more:
['poi','salary', 'deferral_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 
'long_term_incentive', 'shared_receipt_with_poi', 'from_this_person_to_poi', 'from_poi_to_this_person']
and the accuracy went up to 95% HAHAHA!


07/02/2016
Need to get a handle on the dataset. 

I did create a simple NB classifier using only 'salary' and 'poi' features. The accuracy was 0.344827586207 
:) only up from that!

I need a list of the features and maybe a distribution of values. Right, found
explore_enron_data.py. 
The set of possible features:
    salary
    to_messages
    deferral_payments
    total_payments
    exercised_stock_options
    bonus
    restricted_stock
    shared_receipt_with_poi
    restricted_stock_deferred
    total_stock_value
    expenses
    loan_advances
    from_messages
    other
    from_this_person_to_poi
    poi
    director_fees
    deferred_income
    long_term_incentive
    email_address
    from_poi_to_this_person
'NaN' is used as a null value. There are 146 people in the dataset. in general, 
we have money and email data. It is not clear to me what 
'shared_receipt_with_poi' means. That a person was on the same email thread?
 I created a features dict and looked at the raw data. Maybe I'll start with 
total money, and some email to/froms.

I should plot these features to look for outliers; I removed the "Total" from 
the data dict, and then checked the to/from pois, but didn't see any 
outliers. Here are the more prolific emailers:
BECK SALLY W
386
LAVORATO JOHN J
411
LAVORATO JOHN J
528
DELAINEY DAVID W
609
KEAN STEVEN J
387
DIETRICH JANET R
305

