07/22/2016



07/21/2016
I just wanted to look at one more thing: PCA with the DT. Then I will switch to 
SVMs. I am trying to not get too lost in this project :)
hmmmmmm, 
Accuracy: 0.83500       Precision: 0.45455      Recall: 0.36250 F1: 0.40334     F2: 0.37780
I find it rather odd there is no impact at all... 
I rechecked everything, and the code looks right AFAICT.

OK,  I need to move on. Maybe I'll use SVMs as an opportunity to look deeper.


07/20/2016
DISCO!
The new ratios really popped up my p/r:
Accuracy: 0.83500       Precision: 0.45455      Recall: 0.36250 F1: 0.40334     F2: 0.37780
I am putting DT to bed, and will hit some SVM work tomorrow. Then, it is time to move on! 
I am thinking of a completely new project for myself.


07/19/2016
Adding the email ratio features to see if that helps my classifier


07/17/2016
I'm sticking with min_split=3, and adding in the feature for restricted stock helps
accuracy but not p/r:
Accuracy: 0.79707       Precision: 0.29538      Recall: 0.30350 F1: 0.29938     F2: 0.30184
'deferral_payments' instead:
Accuracy: 0.78469       Precision: 0.30272      Recall: 0.30650 F1: 0.30460     F2: 0.30574
wow, really crappy with 'long_term_incentive'
Accuracy: 0.77092       Precision: 0.26670      Recall: 0.27950 F1: 0.27295     F2: 0.27684

Ok, what about just email data?
Even crappier:
Accuracy: 0.78333       Precision: 0.13178      Recall: 0.17000 F1: 0.14847     F2: 0.16068

If I combined I have:
Accuracy: 0.79262       Precision: 0.30383      Recall: 0.26950 F1: 0.28564     F2: 0.27573

I went back to only basic $ features: 'salary', 'exercised_stock_options', 'bonus'
to experiment more with the DT parameters.

with basic $ and only 'shared_receipt_with_poi' and DT with criterion='entropy',
min_samples_split=3, random_state=42,
 Accuracy: 0.79792       Precision: 0.31763      Recall: 0.27300 F1: 0.29363     F2: 0.28089

which is pretty close to the mins needed ("to achieve better than .3 precision and recall")
random_state 
(0)
Accuracy: 0.79531       Precision: 0.30796      Recall: 0.26500 F1: 0.28487     F2: 0.27261
(15)
Accuracy: 0.79738       Precision: 0.31505      Recall: 0.27000 F1: 0.29079     F2: 0.27795
(30)
Accuracy: 0.79369       Precision: 0.30581      Recall: 0.26850 F1: 0.28594     F2: 0.27522
(50)
Accuracy: 0.79923       Precision: 0.32205      Recall: 0.27600 F1: 0.29725     F2: 0.28413

on the forums, some folks created ratios of to_poi/from_poi for use in their features.

I read Raschka's excellent Introduction to NB and Text Classification. I need another 
for DTs. 


07/15/2016
A very long break: husb's grandmother dying, the service, getting back to Seattle, 
getting back to life, getting sick. 

looking at tester.py today and hopefully looking at the changes I need to make
to get the SVM up and running at a decent p/r. Then, I'll try a decision tree 
classifier and then put this class to bed!

Ah, apparently I should have read my last journal entry. 

Here are the results from the DT classifer from tester.py:
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,
            min_samples_split=5, min_weight_fraction_leaf=0.0,
            presort=False, random_state=0, splitter='best')
Accuracy: 0.78929       Precision: 0.25839      Recall: 0.25400 F1: 0.25618     F2: 0.25487
        Total predictions: 14000        True positives:  508    False positives: 1458   
        False negatives: 1492   True negatives: 10542

it looks like my classifier is doing equally poorly on false negs and false pos.
is this a problem with my features? What if I remove the PCA? hm, no change.

OK. Changing the min_samples_split upped the stats, but not meaningfully:
(3)
Accuracy: 0.79271       Precision: 0.27337      Recall: 0.27200 F1: 0.27268     F2: 0.27227
(1)
Accuracy: 0.79200       Precision: 0.28014      Recall: 0.29050 F1: 0.28522     F2: 0.28837

Started looking at my features list. Only looking at $, specifically:
'salary', 'exercised_stock_options', 'bonus'
helps the recall:
(1)
Accuracy: 0.76646       Precision: 0.28069      Recall: 0.33150 F1: 0.30399     F2: 0.31992
(3)
Accuracy: 0.78492       Precision: 0.30736      Recall: 0.31750 F1: 0.31235     F2: 0.31542

OK. Time to go to work


07/08/2016
Still trying to figure out my SVM problems. I have changed the kernel params, to no
effect. 
I switched to experimenting with decision trees.

07/06/2016
Experimenting with types of ML algos. I have been using the GaussianNB originally provided.
I'd like to try an SVM and a Kmeans. Decision tree doesn't seem too interesting here. 

I also tried to add precision and recall measurements to look at the differences between
these evaluations and the accuracy score when the algos change. I got an error
"UndefinedMetricWarning: Precision is ill-defined and being set to 0.0"

The GaussianNB had the following scores
accuracy 0.95
precision 1.0
recall 0.5
F1 0.666666666667

The SVM didn't make any predications. Hm. I can't find out what is up. It makes no predications.

Kmeans didn't work out for me. it predicted all the persons were POIs!! 


07/03/2016
instead of salary, I used 'total_payments' and added 'from_this_person_to_poi'
and 'from_poi_to_this_person'. That bumped my accuracy score up to 0.875!

I'll work on feature selection and PCA today, and see if I cannot come up with some 
interesting features

I was looking to run PCA or RandomizedPCA on the data, I realized I don't really know
 how to use it on the data. I understand the general concept, that it's a technique
for taking many dimensions of a dataset and distilling those dimensions to new features.

hm, I added some features, but the accuracy actually went down :(! The I added loads more:
['poi','salary', 'deferral_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 
'long_term_incentive', 'shared_receipt_with_poi', 'from_this_person_to_poi', 'from_poi_to_this_person']
and the accuracy went up to 95% HAHAHA!


07/02/2016
Need to get a handle on the dataset. 

I did create a simple NB classifier using only 'salary' and 'poi' features. The accuracy was 0.344827586207 
:) only up from that!

I need a list of the features and maybe a distribution of values. Right, found
explore_enron_data.py. 
The set of possible features:
    salary
    to_messages
    deferral_payments
    total_payments
    exercised_stock_options
    bonus
    restricted_stock
    shared_receipt_with_poi
    restricted_stock_deferred
    total_stock_value
    expenses
    loan_advances
    from_messages
    other
    from_this_person_to_poi
    poi
    director_fees
    deferred_income
    long_term_incentive
    email_address
    from_poi_to_this_person
'NaN' is used as a null value. There are 146 people in the dataset. in general, 
we have money and email data. It is not clear to me what 
'shared_receipt_with_poi' means. That a person was on the same email thread?
 I created a features dict and looked at the raw data. Maybe I'll start with 
total money, and some email to/froms.

I should plot these features to look for outliers; I removed the "Total" from 
the data dict, and then checked the to/from pois, but didn't see any 
outliers. Here are the more prolific emailers:
BECK SALLY W
386
LAVORATO JOHN J
411
LAVORATO JOHN J
528
DELAINEY DAVID W
609
KEAN STEVEN J
387
DIETRICH JANET R
305

